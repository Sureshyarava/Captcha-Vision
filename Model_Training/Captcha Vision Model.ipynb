{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d5e9d0-49b9-4627-ac81-81a29d1b0bdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mImage\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras import models, Sequential, layers\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e869c2-3fbc-452a-9ded-31b6d6188844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 version is 4.10.0\n",
      "numpy version is 1.26.4\n",
      "tensorflow version is 2.16.1\n",
      "keras version is 3.3.3\n",
      "pandas version is 2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"cv2 version is {cv2.__version__}\")\n",
    "print(f\"numpy version is {np.__version__}\")\n",
    "print(f\"tensorflow version is {tf.__version__}\")\n",
    "print(f\"keras version is {keras.__version__}\")\n",
    "print(f\"pandas version is {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c1d4dd-4b72-4746-9686-acbcec64f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_Image(name, image):\n",
    "    cv2.imshow(name, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf9ca55-1e7a-45c8-bda9-b74becc5236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = [], []\n",
    "IMAGE_FOLDER = \"../Captcha\\ Processing/generated_single_images\"\n",
    "for name in os.listdir(IMAGE_FOLDER):\n",
    "    path = os.path.join(IMAGE_FOLDER, name)\n",
    "    image = cv2.imread(path)\n",
    "    try:\n",
    "        if image.shape == (50,50,3):\n",
    "            X.append(image)\n",
    "            y.append(name.split(\"_\")[0])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b79bdb1-359b-412b-b945-603f261042a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d1d65f-d7c9-46c2-80c9-bc3003cba8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db11e18-eb0e-46d1-b7ca-e690d012c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "y_one_hot = keras.utils.to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa10dcd-6a82-4fd4-b4da-ba7b126d2c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31704, 50, 50, 3)\n",
      "(31704, 32)\n",
      "(7927, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "train_x,test_x , train_y,test_y = train_test_split(X,y_one_hot,test_size = 0.2)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d028aab6-297b-4e79-b5c0-24d32bdce4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f8a383-08fc-4378-b513-ce5512507ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model():\n",
    "    cnn = Sequential([\n",
    "        layers.Conv2D(16 ,3,padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32,3,padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64,3,padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(200, activation = \"relu\"),\n",
    "        layers.Dense(100, activation = \"relu\"),\n",
    "        layers.Dense(len(unique),activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    cnn.compile(optimizer = \"adam\",\n",
    "               loss = keras.losses.CategoricalCrossentropy(),\n",
    "               metrics = [\"accuracy\"])\n",
    "    \n",
    "    cnn.fit(train_x, train_y, epochs=20)\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589ec7fb-8887-4321-884e-545708a98e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/Machine_Learning_Practice/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 14 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "if \"captcha_vision_model.keras\" not in os.listdir(\"./\"):\n",
    "    cnn = train_model()\n",
    "    cnn.save(\"captcha_vision_model.keras\")\n",
    "else:\n",
    "    cnn = load_model(\"captcha_vision_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "423f4a69-e3d7-44f0-b29a-7debf2d1ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03932895511388779, 0.9911693930625916]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb5c76d-2293-430e-b310-3dbae66286a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(test_x)\n",
    "\n",
    "\n",
    "# cr = classification_report(y_true=test_y, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "751e4b5f-ceb4-402c-9d3f-d7ec20902398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7927, 32)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ace4d9c4-d70b-4ffd-9a43-0da361d17e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = []\n",
    "y_test = []\n",
    "for i in range(len(y_pred)):\n",
    "    pred_y.append(unique[np.argmax(y_pred[i])])\n",
    "    y_test.append(unique[np.argmax(test_y[i])])\n",
    "\n",
    "pred_y = np.array(pred_y)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dbf68c6-ba95-4961-83e9-b30c498ebc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7927,)\n"
     ]
    }
   ],
   "source": [
    "print(pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af619f5f-4cd7-4b17-a72c-64fb168587dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_pred=pred_y, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "492c95f3-acce-499e-9a09-b95063d21ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00       244\n",
      "           3       1.00      1.00      1.00       250\n",
      "           4       1.00      1.00      1.00       252\n",
      "           5       0.97      1.00      0.98       253\n",
      "           6       1.00      1.00      1.00       240\n",
      "           7       1.00      1.00      1.00       277\n",
      "           8       1.00      1.00      1.00       248\n",
      "           9       1.00      1.00      1.00       268\n",
      "           A       1.00      1.00      1.00       227\n",
      "           B       1.00      1.00      1.00       237\n",
      "           C       1.00      0.99      0.99       259\n",
      "           D       1.00      1.00      1.00       229\n",
      "           E       1.00      0.99      0.99       240\n",
      "           F       1.00      1.00      1.00       235\n",
      "           G       0.95      1.00      0.98       245\n",
      "           H       1.00      1.00      1.00       245\n",
      "           J       0.99      0.98      0.98       243\n",
      "           K       0.99      1.00      0.99       262\n",
      "           L       1.00      1.00      1.00       259\n",
      "           M       0.99      1.00      1.00       239\n",
      "           N       0.90      1.00      0.95       272\n",
      "           P       1.00      1.00      1.00       249\n",
      "           Q       1.00      1.00      1.00       232\n",
      "           R       1.00      1.00      1.00       269\n",
      "           S       1.00      0.96      0.98       267\n",
      "           T       1.00      1.00      1.00       240\n",
      "           U       1.00      1.00      1.00       218\n",
      "           V       0.99      0.99      0.99       227\n",
      "           W       1.00      0.99      1.00       252\n",
      "           X       1.00      0.89      0.94       271\n",
      "           Y       1.00      0.99      0.99       254\n",
      "           Z       1.00      1.00      1.00       224\n",
      "\n",
      "    accuracy                           0.99      7927\n",
      "   macro avg       0.99      0.99      0.99      7927\n",
      "weighted avg       0.99      0.99      0.99      7927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af16b36-da10-45bf-a0ca-a7720cdd48cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
